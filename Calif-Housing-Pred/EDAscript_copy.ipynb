{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom EDA script \n",
    "\n",
    "This notebook takes in a clean dataframe and performs exploratory data analysis steps \n",
    "#### Mainly for continuous data \n",
    "\n",
    "- Assumptions\n",
    "  1. There are no missing values in the df\n",
    "  2. The last of the df contains the target variable \n",
    "    \n",
    "#### Task performed \n",
    "1. Extract basic info of the df (df.info)\n",
    "2. Basic descriptive stats (mean, median, quartiles etc.)\n",
    "3. Correlation table + heatmap\n",
    "4. Top features vs. target variable correlation table \n",
    "5. Box plots to observe outliers \n",
    "6. Distribution plots to check skewness \n",
    "7. (sampled) Scatter plots of all features againt the target var. \n",
    "8. Basic regression analysis with statsmodels lib. \n",
    "\n",
    "BEWARE: When this script is run standalone (i.e. not called into another notebook), the DF is undefined. In which case it loads a library dataset from statsmodel and uses that to show the result.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevent libraries \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import statsmodels as sm\n",
    "import time    # allows to pause \n",
    "\n",
    "from statsmodels import datasets\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script is to be inside another notebook where DF has already been defined. If not, use a builtin df for observation\n",
    "try:\n",
    "    DF.info() \n",
    "except:     #load a df from the builtin lib. \n",
    "    Lib_dataset = sm.datasets.macrodata.load_pandas()\n",
    "    DF = Lib_dataset.data\n",
    "    DF.info() \n",
    "\n",
    "targetVarName = DF.columns[-1]\n",
    "\n",
    "print('***The target variable is : ' + targetVarName)  #verifying if it picked the right name\n",
    "\n",
    "print(DF.describe()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see correlation between all variables in the form of heatmap + R values \n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.style.use('ggplot')\n",
    "corr_matrix = DF.corr()\n",
    "corr_matrix_tri = corr_matrix.where(np.tril(np.ones(corr_matrix.shape),k=0).astype(np.bool))\n",
    "heat = sns.heatmap(corr_matrix_tri, annot=True, fmt='.2g',cmap = 'viridis').set(title='Correlation plot')\n",
    "print(\"Correlation between all variables\") \n",
    "plt.show() \n",
    "\n",
    "## List top 5 correlated factors with the target variable \n",
    "\n",
    "k = 6 \n",
    "cols = corr_matrix.abs().nlargest(k, targetVarName, keep = 'all')[targetVarName].index \n",
    "cm = DF[cols].corr()\n",
    "print('Top features correlated to Target (+ve or -ve)' )\n",
    "#print(cm[targetVarName])  \n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "x = cm[targetVarName].to_frame()    #print only first column which has corr with targt var. \n",
    "\n",
    "print(tabulate(x, headers='keys', tablefmt='psql'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now try to spot the outliers by plotting boxplots and distributions \n",
    "import math \n",
    "\n",
    "dfCols = DF.columns.values\n",
    "# print(dfCols)\n",
    "\n",
    "subCol = len(dfCols)  #no of columns in the subplot figure \n",
    "#no of rows will be automatically calculated, accomodating 5 vars per row \n",
    "\n",
    "plt.figure(figsize=(20,12))\n",
    "for i in range(0,len(dfCols)):\n",
    "\n",
    "    if DF[dfCols[i]].dtype == 'float' or DF[dfCols[i]].dtype == 'int':  #only for numeric data\n",
    "        # print(DF[dfCols[i]].dtype)\n",
    "        plt.subplot(math.ceil(subCol/5),5, i+1) \n",
    "        ax = sns.boxplot(data = DF[dfCols[i]], notch = False, palette='colorblind')\n",
    "        ax.set_title(dfCols[i])\n",
    "\n",
    "        sns.set_style('whitegrid')\n",
    "print('BOXPLOTS, EXCLUDING CATEGORICAL FEATURES')\n",
    "plt.show()\n",
    "\n",
    "# Frequency distribution\n",
    "plt.figure(figsize=(20,12))\n",
    "\n",
    "for j in range(0,len(dfCols)):\n",
    "    plt.subplot(math.ceil(subCol/5),5, j+1)\n",
    "    ax = sns.histplot(data = DF[dfCols[j]], kde=True, stat='density') \n",
    "    # ax.set_title(dfCols[i])\n",
    "    sns.set_style('whitegrid')\n",
    "print('DENSITY PLOTS')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It would be unwise to plot all data points if the size is too large. we will take a sample of the data \n",
    "\n",
    "sample_DF = DF.sample(frac=0.5, random_state = 10)\n",
    "plt.figure(figsize=(20,12))\n",
    "\n",
    "for i, feature in enumerate(dfCols):\n",
    "    plt.subplot(math.ceil(subCol/5),5, i+1) \n",
    "    ax = sns.scatterplot(data = sample_DF, x = feature, y = targetVarName, palette = 'cool')\n",
    "print('SCATTER PLOTS')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
